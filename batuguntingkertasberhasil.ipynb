{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "nama: Bintang Raga Pratama\n",
        "email : bintangraga152@gmail.com\n",
        "domisili kota : Surabaya\n"
      ],
      "metadata": {
        "id": "E3C0kNw3XOET"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kN28z65M5R81"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# link tempat dataset rockpaperscissors.zip berada\n",
        "url = \"https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip\"\n",
        "\n",
        "!wget {url} -O rockpaperscissors.zip\n",
        "\n",
        "# Ekstrak file zip\n",
        "local_zip = 'rockpaperscissors.zip'  #\n",
        "base_dir = '/tmp/rockpaperscissors/rps-cv-images'\n",
        "zip_extract = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_extract.extractall('/tmp')\n",
        "zip_extract.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mt6aY6D55Xz9",
        "outputId": "396a9984-8589-475c-e6a2-8cf63c734758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-09 07:52:26--  https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/391417272/7eb836f2-695b-4a46-9c78-b65867166957?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240509%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240509T075227Z&X-Amz-Expires=300&X-Amz-Signature=00e4bec0206e8021a074be7869419b8872d81b19ad74d69b5b6cfb838dccb18d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=391417272&response-content-disposition=attachment%3B%20filename%3Drockpaperscissors.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-05-09 07:52:27--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/391417272/7eb836f2-695b-4a46-9c78-b65867166957?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240509%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240509T075227Z&X-Amz-Expires=300&X-Amz-Signature=00e4bec0206e8021a074be7869419b8872d81b19ad74d69b5b6cfb838dccb18d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=391417272&response-content-disposition=attachment%3B%20filename%3Drockpaperscissors.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 322873683 (308M) [application/octet-stream]\n",
            "Saving to: ‘rockpaperscissors.zip’\n",
            "\n",
            "rockpaperscissors.z 100%[===================>] 307.92M   137MB/s    in 2.2s    \n",
            "\n",
            "2024-05-09 07:52:29 (137 MB/s) - ‘rockpaperscissors.zip’ saved [322873683/322873683]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('/tmp/rockpaperscissors')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npEE0Sdc51z9",
        "outputId": "909cc6c8-1d3a-4a69-ef86-9d46ac79d28d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['paper', 'README_rpc-cv-images.txt', 'scissors', 'rps-cv-images', 'rock']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# augmentation gambar\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range = 20,\n",
        "    horizontal_flip = True,\n",
        "    shear_range = 0.2,\n",
        "    fill_mode = 'wrap',\n",
        "    validation_split = 0.4\n",
        ")\n",
        "train_datagen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZNHD-Bz6O13",
        "outputId": "2157764e-0a3c-44fa-d681-926d98dcf896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.preprocessing.image.ImageDataGenerator at 0x7d8700dafb50>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size = (100, 150),\n",
        "    class_mode = 'categorical',\n",
        "    subset = 'training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size = (100, 150),\n",
        "    class_mode = 'categorical',\n",
        "    subset = 'validation'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6xJ5lKY6YL3",
        "outputId": "f0dc1cfc-0f41-46d8-8c2e-744a27becc3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1314 images belonging to 3 classes.\n",
            "Found 874 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (100, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(3, activation = 'softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "K7sTYesO6eCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# menghitung fungsi\n",
        "model.compile(\n",
        "    loss = 'categorical_crossentropy',\n",
        "    optimizer = tf.optimizers.Adam(),\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "AprZyKwK6jW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_threshold = 0.98\n",
        "\n",
        "class my_callbacks(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs.get('accuracy') >= accuracy_threshold:\n",
        "            print('\\nFor Epoch', epoch, '\\nAccuracy has reached = %2.2f%%' % (logs['accuracy'] * 100), 'training has been stopped.')\n",
        "            self.model.stop_training = True\n",
        "\n",
        "callbacks = my_callbacks()\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=25,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=5,\n",
        "    verbose=2,\n",
        "    callbacks=[callbacks]\n",
        ")\n",
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fENwqkjK63do",
        "outputId": "6ba10136-529a-4741-ec81-c2164d243af7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "25/25 - 36s - loss: 0.1285 - accuracy: 0.9494 - val_loss: 0.1016 - val_accuracy: 0.9688 - 36s/epoch - 1s/step\n",
            "Epoch 2/20\n",
            "25/25 - 40s - loss: 0.1014 - accuracy: 0.9636 - val_loss: 0.2109 - val_accuracy: 0.9375 - 40s/epoch - 2s/step\n",
            "Epoch 3/20\n",
            "25/25 - 34s - loss: 0.0849 - accuracy: 0.9688 - val_loss: 0.1753 - val_accuracy: 0.9625 - 34s/epoch - 1s/step\n",
            "Epoch 4/20\n",
            "25/25 - 43s - loss: 0.0844 - accuracy: 0.9737 - val_loss: 0.0768 - val_accuracy: 0.9625 - 43s/epoch - 2s/step\n",
            "Epoch 5/20\n",
            "25/25 - 37s - loss: 0.0851 - accuracy: 0.9753 - val_loss: 0.1662 - val_accuracy: 0.9375 - 37s/epoch - 1s/step\n",
            "Epoch 6/20\n",
            "\n",
            "For Epoch 5 \n",
            "Accuracy has reached = 98.12% training has been stopped.\n",
            "25/25 - 34s - loss: 0.0613 - accuracy: 0.9812 - val_loss: 0.0691 - val_accuracy: 0.9875 - 34s/epoch - 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  # prediksi gambar\n",
        "  path = fn\n",
        "  img_source = image.load_img(path, target_size = (100, 150))\n",
        "  imgplot = plt.imshow(img_source)\n",
        "  x = image.img_to_array(img_source)\n",
        "  x = np.expand_dims(x, axis = 0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size = 10)\n",
        "\n",
        "  print(fn)\n",
        "  if classes[0, 0] == 1:\n",
        "    print('paper')\n",
        "  elif classes[0, 1] == 1:\n",
        "    print('rock')\n",
        "  elif classes[0, 2] == 1:\n",
        "    print('scissors')"
      ],
      "metadata": {
        "id": "k4Rv-mUx_dAe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}